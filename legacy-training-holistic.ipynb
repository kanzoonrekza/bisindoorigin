{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for training the holistic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pembuatan Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "import io\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, log_loss, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "n = 1  # Data duplication\n",
    "handsOnly = True  # Whether to use only hands or not\n",
    "learning_rate = 0.0001\n",
    "epoch = 10\n",
    "\n",
    "FOLDER_NAME = 'dataset'\n",
    "ALL_CLASSES = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25}\n"
     ]
    }
   ],
   "source": [
    "# Create label map, representing each class as a number\n",
    "label_map = {}\n",
    "for (root, folders, files) in os.walk(FOLDER_NAME):\n",
    "    for foldername in folders:\n",
    "        if foldername in ALL_CLASSES:\n",
    "            label_map[foldername] = ALL_CLASSES.index(foldername)\n",
    "\n",
    "print(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files: 0 --- dataset\n",
      "Total files: 50 --- dataset\\a\n",
      "Total files: 50 --- dataset\\b\n",
      "Total files: 50 --- dataset\\c\n",
      "Total files: 50 --- dataset\\d\n",
      "Total files: 50 --- dataset\\e\n",
      "Total files: 50 --- dataset\\f\n",
      "Total files: 50 --- dataset\\g\n",
      "Total files: 50 --- dataset\\h\n",
      "Total files: 50 --- dataset\\i\n",
      "Total files: 50 --- dataset\\j\n",
      "Total files: 50 --- dataset\\k\n",
      "Total files: 50 --- dataset\\l\n",
      "Total files: 50 --- dataset\\m\n",
      "Total files: 50 --- dataset\\n\n",
      "Total files: 50 --- dataset\\o\n",
      "Total files: 50 --- dataset\\p\n",
      "Total files: 50 --- dataset\\q\n",
      "Total files: 50 --- dataset\\r\n",
      "Total files: 50 --- dataset\\s\n",
      "Total files: 50 --- dataset\\t\n",
      "Total files: 50 --- dataset\\u\n",
      "Total files: 50 --- dataset\\v\n",
      "Total files: 50 --- dataset\\w\n",
      "Total files: 50 --- dataset\\x\n",
      "Total files: 50 --- dataset\\y\n",
      "Total files: 50 --- dataset\\z\n",
      "(1300, 14, 126)\n",
      "(1300,)\n"
     ]
    }
   ],
   "source": [
    "# Get all datset data with its label and put it in a list\n",
    "sequence, label = [], []\n",
    "target_length = 14\n",
    "for (root, folders, files) in os.walk(FOLDER_NAME):\n",
    "    total_file = 0\n",
    "    for filename in files:\n",
    "        file_path = os.path.join(os.path.relpath(\n",
    "            root, FOLDER_NAME), filename)\n",
    "        if (filename.endswith('.npy') and os.path.split(file_path)[0] in ALL_CLASSES):\n",
    "            res = np.load(f'{FOLDER_NAME}/{file_path}')\n",
    "            for _ in range(target_length-res.shape[0]):\n",
    "                res = np.vstack((res, res[-1, :]))\n",
    "            if(handsOnly):\n",
    "                res = res[:, -126:]\n",
    "            sequence.append(np.array(res))\n",
    "            label.append(label_map[os.path.basename(root[-1])])\n",
    "            total_file += 1\n",
    "    print(f\"Total files: {total_file} --- {root}\")\n",
    "\n",
    "print(np.array(sequence).shape)\n",
    "print(np.array(label).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1300, 14, 126)\n",
      "(1300,)\n"
     ]
    }
   ],
   "source": [
    "sequence = np.concatenate([sequence] * n, axis=0)\n",
    "label = np.concatenate([label] * n, axis=0)\n",
    "\n",
    "\n",
    "print(np.array(sequence).shape)\n",
    "print(np.array(label).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1040, 14, 126) (260, 14, 126)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(sequence), tf.keras.utils.to_categorical(\n",
    "    np.array(label).astype(int), num_classes=np.array(ALL_CLASSES).shape[0], dtype='float32'), test_size=0.2)\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logs\\126-tanh-lr-0001-dupli-1-10-epoch-20240929-115115\n"
     ]
    }
   ],
   "source": [
    "training_phase = str(np.array(sequence).shape[2]) + \"-tanh-lr-\" + str(learning_rate).replace(\"0.\", \"\") + \"-dupli-\" + str(n) + \"-\" + str(epoch) + \"-epoch-\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = os.path.join('Logs', training_phase)\n",
    "tb_callback = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "print(log_dir)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True,\n",
    "               activation='tanh', input_shape=(14, np.array(sequence).shape[2])))\n",
    "model.add(LSTM(64, return_sequences=True, activation='tanh'))\n",
    "model.add(LSTM(64, return_sequences=False, activation='tanh'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(np.array(ALL_CLASSES).shape[0], activation='softmax'))\n",
    "\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "33/33 [==============================] - 8s 17ms/step - loss: 3.2507 - categorical_accuracy: 0.0356\n",
      "Epoch 2/10\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 3.2329 - categorical_accuracy: 0.0404\n",
      "Epoch 3/10\n",
      "33/33 [==============================] - 1s 22ms/step - loss: 3.2059 - categorical_accuracy: 0.0404\n",
      "Epoch 4/10\n",
      "33/33 [==============================] - 1s 44ms/step - loss: 3.1667 - categorical_accuracy: 0.0490\n",
      "Epoch 5/10\n",
      "33/33 [==============================] - 1s 34ms/step - loss: 3.1113 - categorical_accuracy: 0.0798\n",
      "Epoch 6/10\n",
      "33/33 [==============================] - 1s 24ms/step - loss: 3.0378 - categorical_accuracy: 0.1087\n",
      "Epoch 7/10\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 2.9416 - categorical_accuracy: 0.1269\n",
      "Epoch 8/10\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 2.8204 - categorical_accuracy: 0.1865\n",
      "Epoch 9/10\n",
      "33/33 [==============================] - 1s 32ms/step - loss: 2.6887 - categorical_accuracy: 0.1990\n",
      "Epoch 10/10\n",
      "33/33 [==============================] - 1s 23ms/step - loss: 2.5654 - categorical_accuracy: 0.2115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21a0fc8a850>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=epoch, callbacks=[\n",
    "          tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 14, 64)            48896     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 14, 64)            33024     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 26)                858       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,042\n",
      "Trainable params: 122,042\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f'{log_dir}/action.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluasi Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kanzoon\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Kanzoon\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Kanzoon\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Kanzoon\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "phase_dir = f'Logs/{training_phase}'\n",
    "if not os.path.exists(phase_dir):\n",
    "    os.makedirs(phase_dir)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "classes = np.unique(y_true)\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred_classes)\n",
    "precision = precision_score(y_true, y_pred_classes, average='weighted')\n",
    "recall = recall_score(y_true, y_pred_classes, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
    "loss = log_loss(y_true, y_pred, labels=classes)\n",
    "\n",
    "# Redirect stdout to a string buffer\n",
    "old_stdout = sys.stdout\n",
    "sys.stdout = buffer = io.StringIO()\n",
    "\n",
    "print(f\"Training Phase: {training_phase}\\n\\n\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Loss: {loss}\")\n",
    "\n",
    "report = classification_report(y_true, y_pred_classes)\n",
    "\n",
    "sys.stdout = old_stdout\n",
    "output = buffer.getvalue()\n",
    "\n",
    "# Save the output to a uniquely named text file in the Logs directory\n",
    "log_filename = f'{phase_dir}/summary.txt'\n",
    "\n",
    "with open(log_filename, 'w') as f:\n",
    "    f.write(output)\n",
    "    f.write(\"\\n\")\n",
    "    f.write(report)\n",
    "    \n",
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True, square=True, linewidths=0,\n",
    "            xticklabels=[f'{ALL_CLASSES[cls]}' for cls in np.unique(y_true)],\n",
    "            yticklabels=[f'{ALL_CLASSES[cls]}' for cls in np.unique(y_true)])\n",
    "\n",
    "\n",
    "# Add labels for axes\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "\n",
    "# Save the figure as a PDF\n",
    "plt.savefig(f'{phase_dir}/confusion_matrix.pdf', format='pdf')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
